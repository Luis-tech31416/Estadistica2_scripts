---
title: "Examen 1, versión B. Regresión lineal simple"
author: "Gonzalo Pérez, Luis Sánchez, Gabriel Martínez, Dioney Rosas y Leonardo de la Cruz"
date: "19 de noviembre de 2021"
output:
  html_document:
    df_print: paged
  pdf_document: 
    keep_tex: yes
    includes:
urlcolor: blue
---

```{r setup, include=FALSE}
rm(list = ls(all.names = TRUE))
gc()
library(reticulate) # Path to python3.exe

knitr::opts_chunk$set(echo = F, warning = F, message = F, error = F, fig.height = 4, fig.width = 8)
library(xtable)
library(knitr)
library(tidyverse)
library(latex2exp)
options(digits=2)
set.seed(20202)
```


El examen se deberá subir al classroom antes de las 11:59 PM del 1 de diciembre de 2021. Todas las preguntas tienen el mismo valor.

Favor de argumentar con detalle las respuestas.

NOTA. En caso de que se identifiquen respuestas iguales en otros examenes, se procederá a la anulación de los examenes involucrados.

NOTA. Incluir el(los) nombre(s) completo(s) de la(s) persona(s) que está(n) resolviendo los ejercicios. Equipos de máximo tres integrantes.

Usar una confianza de 95% o una significancia de .05 en los casos en donde no se requiera otro nivel de forma explícita. En el caso de realizar alguna transformación de las variables, se tiene que hacer explícita la variable que se usa y la interpretación en las pruebas de hipótesis o intervalos de confianza.

### 1. Regresión a través del origen. 
Ocasionalmente, un modelo en
donde el valor del intercepto es conocido a priori y es igual a
cero puede ser apropiado.  Este modelo está dado por:

$$y_{i}=\beta x_{i}+\varepsilon_{i}, \qquad  i=1,...,n,$$

\noindent donde $\varepsilon_1, \varepsilon_2, ..., \varepsilon_n$ son variables independientes tal que $\varepsilon_i \sim N(0, \sigma^2) \;\;  \forall    \; \; i= 1,...,n.$ 

En general $\sigma^2$ es desconocida, pero en lo que sigue suponga que es conocida. 

i) Encuentre el estimador de
$\beta$ obtenido por el método de máxima verosimilitud, $\widehat{\beta}$. 
i) Encuentre la expresión de la varianza de $\widehat{\beta}$.
i) Demuestre que $\widehat{\beta}$ es el UMVUE de $\beta$, es decir, que es el mejor estimador insesgado de $\beta$.


### 2.


Considere el modelo de regresión 
$$y_i=\beta_0 +
\beta_1 x_i + \varepsilon_i,$$ 

donde $E(\varepsilon_i)=0, \; V(\varepsilon_i)=\sigma^2 \;\; \text{y} \;\; Cov(\varepsilon_i, \varepsilon_j)=0 \;  \forall \; i\neq j;   \; \; i,j = 1,...,n$. 
  
Calcular $Cov(e_i, \widehat{\beta}_0)$, donde $e_i=y_i-\widehat{y}_i$ y $\widehat{y}_i=\widehat{\beta}_0+\widehat{\beta}_1x_i$, con $\widehat{\beta}_0$ y $\widehat{\beta}_1$ los estimadores de los parámetros del modelo.

Hint: Recordar que $\widehat{y}_i$, $\widehat{\beta}_0$ y $\widehat{\beta}_1$  se pueden escribir como una combinación lineal de las $y_{i's}$.



### 3. Problema Anova. Equivalencia con la prueba t para comparar dos poblaciones.
Sea $X_{1},...,X_{n}$ una m.a. de la distribución $N(\mu_x,\sigma^2)$ y $Y_{1},...,Y_{m}$ una m.a. de la distribución $N(\mu_y,\sigma^2)$, ambas muestras aleatorias son independientes entre sí. La prueba t se usa bajo este contexto para contrastar, por ejemplo:

$$H_0: \mu_x=\mu_y \quad \quad vs \quad \quad  H_a: \mu_x \neq \mu_y.$$
Sea $t$ la estadística asociada a la prueba t antes mencionada. 

i. Considere una variable $Z$ tal que $Z=1$ si la observación es de la población con distribución $N(\mu_x,\sigma^2)$ y $Z=0$ si la observación es de la población con distribución $N(\mu_y,\sigma^2)$. 
 Considere el modelo de regresión lineal simple:
$$w_j=\beta_0 +
\beta_1 z_j + \varepsilon_j,$$ 
 donde $\varepsilon_1, \varepsilon_2, ..., \varepsilon_{n+m}$ son variables independientes tal que $\varepsilon_j \sim N(0, \sigma^2) \;\;  \forall    \; \; j= 1,...,n+m.$ Asuma que las primeras $n$ observaciones son las que tienen valor $Z=1$ y el resto son las que tienen valor $Z=0$. Indique cuál es la distribución de $W$ para cada valor de la variable $Z$, haciendo énfasis en indicar la relación que esto implica entre $\mu_x$ y $\mu_y$ con $\beta_0$ y $\beta_1$. 

i. En términos de los parámetros del modelo de regresión lineal simple en I), indique cómo se deben escribir las hipótesis
$$H_0: \mu_x=\mu_y \quad \quad vs \quad \quad  H_a: \mu_x \neq \mu_y.$$
Además dé la expresión de la estadística asociada a la prueba que se usaría para contrastar estas hipótesis en el contexto del modelo de regresión lineal simple. 

i. Demuestre que la estadística encontrada en II) es equivalente (en valor absoluto) a la estadística $t$ asociada a la prueba t.

Hint: Puede usar todas las expresiones ya encontradas en clase para los estimadores y pruebas de hipótesis. Encuentre una expresión para $\widehat{\beta}_1$ en términos de $X_{i}$ y $Y_{i}$ tomando ventaja de que $z_j$ sólo toma el valor 0 o 1; además use una expresión para  $\widehat{w}_j$ que sólo depende de $\widehat{\beta}_1$, en particular identificar $\widehat{E}(W|Z=1)$ y $\widehat{E}(W|Z=0)$ en términos de $X_{i}$ y $Y_{i}$.

### 4. Expresión alternativa para $R^2$

Considere el coeficiente de correlación muestral o de Pearson para dos variables $X$ y $Y$:

\begin{alignat}{4} r_{xy}=&\dfrac{\sum_{i=1}^{n}(x_i-\overline{X})(y_i-\overline{Y})}{(\sum_{i=1}^{n}(x_i-\overline{X})^2\sum_{i=1}^{n}(y_i-\overline{Y})^2)^{1/2}}, \label{eqn:reglinsimrxy}
\end{alignat}

Demuestre que
\begin{alignat}{4} R^2=& r^2_{y\widehat{y}}, \label{eqn:reglinsimR2ryyhat}
\end{alignat}
donde,

\begin{alignat}{4} r_{y\widehat{y}}=&\dfrac{\sum_{i=1}^{n}(y_i-\overline{Y})(\widehat{y}_i-\overline{\widehat{y}})}{(\sum_{i=1}^{n}(y_i-\overline{Y})^2\sum_{i=1}^{n}(\widehat{y}_i-\overline{\widehat{y}})^2)^{1/2}}. \label{eqn:reglinsimryyhat}
\end{alignat}

Hint: Puede usar las propiedades a) a d) que se obtienen de las ecuaciones normales, expresiones (25) y (26) de las notas. 

\textbf{4. Expresión alternativa para $R^{2}$}

\medskip
Claim: $R^{2}=r^{2}_{y\hat{y}}$

### Demostración:

Para cualquier  $i\in\{1,\ldots,n\}$ podemos observar que

\begin{align*}
    \hat{y_{i}}-\bar{\hat{y}}&=\hat{y_{i}}-\frac{1}{n}\sum_{i=1}^{n}\hat{y_{i}}=\hat{y_{i}}-\frac{1}{n}\sum_{i=1}^{n}(\hat{\beta_{0}}+\hat{\beta_{1}}x_{i})\\
    &=\hat{\beta_{0}}+\hat{\beta_{1}}x_{i}-\hat{\beta_{0}}-\hat{\beta_{1}}\cdot\frac{1}{n}\sum_{i=1}^{n}x_{i}\\
    &=\hat{\beta_{1}}x_{i}-\hat{\beta_{1}}\cdot\bar{x}\\
    &=\hat{\beta_{1}}(x_{i}-\bar{x})
\end{align*}

donde utilizamos que $\hat{y_{i}}=\hat{\beta_{0}}+\hat{\beta_{1}}x_{i}$ por ecuación (11) en (Pérez [1], 2021, p.7). Luego, con base en el resultado de la ecuación anterior se tiene que

\begin{align*}
    r^{2}_{y\hat{y}}&=\frac{\left(\sum_{i=1}^{n} (y_{i}-\bar{y})(\hat{y_{i}}-\bar{\hat{y}})\right)^{2}}{\sum_{i=1}^{n}(y_{i}-\bar{y})^{2}\sum_{i=1}^{n}(\hat{y_{i}}-\bar{\hat{y}})^{2}}=\frac{\left(\sum_{i=1}^{n} (y_{i}-\bar{y})[\hat{\beta_{1}}(x_{i}-\bar{x})]\right)^{2}}{\sum_{i=1}^{n}(y_{i}-\bar{y})^{2}\sum_{i=1}^{n}[\hat{\beta_{1}}(x_{i}-\bar{x})]^{2}}\\
    &=\frac{\hat{\beta_{1}}^{2}\left(\sum_{i=1}^{n} (y_{i}-\bar{y})(x_{i}-\bar{x})\right)^{2}}{\hat{\beta_{1}}^{2}\sum_{i=1}^{n}(y_{i}-\bar{y})^{2}\sum_{i=1}^{n}(x_{i}-\bar{x})^{2}}=\frac{\sum_{i=1}^{n} (y_{i}-\bar{y})(x_{i}-\bar{x})}{\sum_{i=1}^{n}(x_{i}-\bar{x})^{2}}\cdot \frac{\sum_{i=1}^{n} (y_{i}-\bar{y})(x_{i}-\bar{x})}{\sum_{i=1}^{n}(y_{i}-\bar{y})^{2}}\\
    &\overset{(21)}{=}\hat{\beta_{1}}\cdot \frac{\sum_{i=1}^{n} (y_{i}-\bar{y})(x_{i}-\bar{x})}{\sum_{i=1}^{n}(y_{i}-\bar{y})^{2}}
\end{align*}

Por lo tanto

\begin{equation}
    r^{2}_{y\hat{y}}=\hat{\beta_{1}}\cdot \frac{\sum_{i=1}^{n} (y_{i}-\bar{y})(x_{i}-\bar{x})}{\sum_{i=1}^{n}(y_{i}-\bar{y})^{2}} \ \ \ \ \ \ \ \ \ (\ast)
\end{equation}

Por otro lado veamos que

\begin{align*}
    \sum_{i=1}^{n}(\hat{y_{i}}-\bar{y})^{2}\overset{(11)}{=}\sum_{i=1}^{n}(\hat{\beta_{0}}+\hat{\beta_{1}}x_{i}-\bar{y})^{2}\overset{(19)}{=}\sum_{i=1}^{n}[(\bar{y}-\hat{\beta_{1}}\bar{x})+\hat{\beta_{1}}x_{i}-\bar{y}]^{2}=\hat{\beta_{1}}^{2}\sum_{i=1}^{n}(x_{i}-\bar{x})^{2}
\end{align*}

Así, la expresión para $R^{2}$ es ahora de la forma

\begin{equation}
    R^{2}=\frac{\sum_{i=1}^{n}(\hat{y_{i}}-\bar{y})^{2}}{\sum_{i=1}^{n}(y_{i}-\bar{y})^{2}}=\frac{\hat{\beta_{1}}^{2}\sum_{i=1}^{n}(x_{i}-\bar{x})^{2}}{\sum_{i=1}^{n}(y_{i}-\bar{y})^{2}} \ \ \ \ \ \ (\ast\ast)
\end{equation}

Comparando las ecuaciones $(\ast)$ y $(\ast\ast)$ deducimos que basta con probar la igualdad

$$
\sum_{i=1}^{n} (y_{i}-\bar{y})(x_{i}-\bar{x})=\hat{\beta_{1}}\cdot \sum_{i=1}^{n}(x_{i}-\bar{x})^{2}
$$

la cual trivialmente se cumple por la mera definición de la $\hat{\beta_{1}}$ (por ecuación (21) en (Pérez [1], 2021, p.8)), esto es

$$
\hat{\beta_{1}}\cdot \sum_{i=1}^{n}(x_{i}-\bar{x})^{2}=\frac{\sum_{i=1}^{n} (y_{i}-\bar{y})(x_{i}-\bar{x})}{\sum_{i=1}^{n}(x_{i}-\bar{x})^{2}}\cdot\sum_{i=1}^{n}(x_{i}-\bar{x})^{2}=\sum_{i=1}^{n} (y_{i}-\bar{y})(x_{i}-\bar{x})
$$

En conclusión $R^{2}=r^{2}_{y\hat{y}}$. $\hspace{17cm} \square$


## Referencias

* [1] Pérez, Gonzalo. (2021). _Notas de Modelos No Paramétricos y de Regresión_.

### 5. Problema ANOVA. Medicamentos

Suponga que un grupo de investigadores está probando un nuevo medicamento para tratar a pacientes con la enfermedad Covid-19. El estudio es muy importante pues teóricamente se espera que ese medicamento reduzca la carga viral y este estudio podría servir para cambiar la forma en la que se trata la enfermedad. El archivo Ejercicio5B.csv contiene la información que se ha obtenido  en un grupo de pacientes que han dado positivo al virus: $Y$ es la carga viral observada después de 48 hrs de aplicar el medicamento y $Med$ es una variable con dos  niveles dependiendo si se aplicó o no el nuevo medicamento. Se sabe que tener una menor carga viral evita que se desarrolle una versión grave de la enfermedad y los investigadores están concentrados en probar que los pacientes que recibieron el medicamento tienen menor carga viral que los que sólo recibieron placebo. 

i. Realice un análisis descriptivo y/o la visualización de los datos
ii. Escriba la prueba asociada para argumentar en favor o no de la afirmación de los investigadores. Para esto deberá indicar qué modelo podría usar y cuales son los supuestos de éste.
iii. Lleve a cabo la prueba de hipótesis, justificando que los supuestos del modelo que está usando son válidos. Dé la interpretación de los resultados.
iv. Suponga ahora que dada la importancia del estudio, le han vuelto a preguntar si los resultados en el inciso III) son contundentes. Para esto, usted ha decidido analizar más el proceso de generación de los datos y ha platicado con los investigadores, logrando que le compartan una nueva variable $Edad$. Realice un análisis descriptivo y/o la visualización de los datos incluyendo esta nueva información. Comente lo que observe analizando si las conclusiones en III) se pueden **atribuir** al medicamento. 
v. Dependiendo de lo observado en IV) y si considera necesario, repita los incisos II) y III) y concluya. 


**--Solución:--** 

```{r include=FALSE}
# Carga de los datos
Datos <- read.csv("Ejercicio5B.csv", header = TRUE)
# Vemos brevemente cómo son nuestros datos
str(Datos)
# Med no es de tipo factor
levels(Datos$Med)
# Convertimos la variable Med a tipo factor
Datos$Med <- as.factor(Datos$Med)
levels(Datos$Med) <- list(Placebo="No", Medicamento="Si")
```

i. _Realice un análisis descriptivo y/o la visualización de los datos:_

```{r include=FALSE}
library(lmtest)
library(car)
library(nortest)
library(normtest)
library(broom)
```

Comenzamos por ver gráficamente el comportamiento de nuestros datos:

```{r}
boxplot(Y ~ Med, data = Datos, col = "white", outline=FALSE)
stripchart(Y ~ Med, data = Datos,
           method = "jitter",
           pch = 19,
           col = c(4,2),
           vertical = TRUE,
           add = TRUE)
```

Notamos a primera instancia que el rango intercuartílico del primer boxplot es mayor respecto al segundo, además los bigotes del primero son más largos respecto al segundo. Así, tenemos que hay más variabilidad en los datos de los pacientes que recibieron el placebo respecto a los datos de los pacientes que recibieron el medicamento. 

Además de notar cierta simetría en los datos, puede observarse que la mediana de la carga viral $Y$ es mayor en aquellos pacientes que recibieron el placebo versus la mediana de la carga viral de los que recibieron el medicamento. Para fines prácticos puede decirse que en promedio la carga viral es mayor en los pacientes que recibieron el placebo respecto a los que recibieron el medicamento, lo cual representa un argumento a favor de la hipótesis de los investigadores.

ii. _Escriba la prueba asociada para argumentar en favor o no de la afirmación de los investigadores. Para esto deberá indicar qué modelo podría usar y cuales son los supuestos de éste_:


Consideraremos el ajuste del modelo

```{r}
fit <- lm(Y ~ Med, data=Datos)
summary(fit)
```

del cual se extraen los valores $\hat{\beta_{0}}=15.759$ y $\hat{\beta_{1}}=-0.640$, de donde

* $\mathbb{E}[\textrm{carga viral};\textrm{placebo}]=\mathbb{E}[z=0]=\hat{\beta_{0}}=15.759=\mu_{1}$

* $\mathbb{E}[\textrm{carga viral};\textrm{Medicamento}]=\mathbb{E}[z=1]=\hat{\beta_{0}}+\hat{\beta_{1}}=15.759-0.640=15.119=\mu_{2}$

Se tiene entonces, bajo este ajuste del modelo, que $\mu_{1}>\mu_{2}$. No obstente, el hecho anterior no puede contemplarse si los supuesto del modelo propuesto no se están cumpliendo. Por ello efectuaremos un **análisis de supuestos**:

<ul>
<li> **Homocedasticidad**: Comenzamos por visualizar la gráfica que ``R`` trae por defecto

```{r}
plot(fit,3)
```

observándose una "nube de puntos" muy parecida en ambos casos, lo que representa un indicio a favor de este supuesto. Complementamos realizando dos pruebas de hipótesis


```{r}
lmtest::bptest(fit)
car::ncvTest(fit)
```

en ambos casos no se rechaza $H_{0}$, $i.e.$ no hay evidencia suficiente en contra de la homocedasticidad. Finalmente complementamos realizando una _prueba por grupos_ donde se contrasta 

$$
H_{0}: \sigma_{1}^{2}=\sigma_{2}^{2}\ \ vs \ \ H_{a}: \sigma_{1}^{2}\neq\sigma_{2}^{2} 
$$

Usamos

```{r}
bartlett.test(Y ~ Med, data=Datos)

# No paramétrica
fligner.test(Y ~ Med, data=Datos)
```

no rechazándose $H_{0}$ en las pruebas. Por tanto, es plausible asumir que este supuesto es válido dentro del modelo.
</li>
<li> **Normalidad**: Visualizamos inicialmente la Q-Qplot que ``R`` trae por defecto

```{r}
plot(fit,2)
```

observándose un comportamiento muy próximo de los datos a la diagonal, lo cual parece indicar que el supuesto de la normalidad es válido. Complementamos realizando pruebas de hipótesis

```{r}
# Cálculo de los errores
Datosfit=augment(fit)

# Shapiro-Wilk
shapiro.test(Datosfit$.std.resid)

# Kolmogorov-Smirnov
nortest::lillie.test(Datosfit$.std.resid)

# Jarque-Bera
normtest::jb.norm.test(Datosfit$.std.resid)
```

en las tres se consigue no rechazar $H_{0}$, $i.e$ es admisible asumir la normalidad de los datos. Finalmente complementamos efectuando la prueba de normalidad por grupos, esto es, realizaremos las tres pruebas anteriores para cada grupo en particular. Resumimos lo obtenido en las pruebas:

```{r include=FALSE}
# Placebo:
# Shapiro-Wilk
shapiro.test(Datos$Y[Datos$Med=="Placebo"])

# Kolmogorov-Smirnov
nortest::lillie.test(Datos$Y[Datos$Med=="Placebo"])

# Jarque-Bera
normtest::jb.norm.test(Datos$Y[Datos$Med=="Placebo"])

# Medicamento
# Shapiro-Wilk
shapiro.test(Datos$Y[Datos$Med=="Medicamento"])

# Kolmogorov-Smirnov
nortest::lillie.test(Datos$Y[Datos$Med=="Medicamento"])

# Jarque-Bera
normtest::jb.norm.test(Datos$Y[Datos$Med=="Medicamento"])
```

```{r results='hold'}
Prueba <- c("Shapiro-Wilk", "Kolmogorov-Smirnov", "Jarque-Bera")
Medicamento <- c("p-value=1", "p-value=0.9", "p-value=1")
Placebo <- c("p-value=0.6", "p-value=0.8", "p-value=0.6")
c <-list()
c0 <- rbind(c,Prueba)
c2 <- rbind(c0,Medicamento)
c3 <- rbind(c2,Placebo)
c3
```

en todas y cada una no se rechaza $H_{0}$. Tomamos pues como válido el supuesto de la normalidad.

En conclusión tenemos que los supuestos son válidos en el modelo propuesto. Por lo tanto, puede considerarse que $\mu_{1}>\mu_{2}$ de acuerdo a los valores de $\hat{\beta_{0}}$ y $\hat{\beta_{1}}$ obtenidos por el modelo propuesto, lo cual argumenta en favor de la afirmación de los investigadores
</li>
</ul>

iii. _Lleve a cabo la prueba de hipótesis, justificando que los supuestos del modelo que está usando son válidos. Dé la interpretación de los resultados_

Por inciso anterior sabemos que los supuestos del modelo pueden asumirse como válidos, por ello es posible considerar la prueba 

$$
H_{0}: \mu_{1}\geq \mu_{2}\ \ \ \ \ vs\ \ \ \ \  H_{a}: \mu_{1}<\mu_{2} 
$$

que equivalentemente 

$$
H_{0}: 0\geq \hat{\beta_{1}}\ \ \ \ \ vs\ \ \ \ \  H_{a}: \hat{\beta_{1}}>0 
$$

```{r include=FALSE}
# Utilizamos el siguiente paquete
library(multcomp)

#theta = zo*bo + z1*b1
MatZ0Z1=matrix(c(0,1), ncol=2, nrow=1)

# El valor con el que comparamos a b1:
c = 0
```

De tal manera considerando en el modelo $\theta=Z_{0}\beta_{0}+Z_{1}\beta_{1}$ para $Z_{0}=0$ y $Z_{1}=1$ obtenemos que

```{r}
prueba1=glht(fit, linfct=MatZ0Z1, rhs=c, alternative ="greater")
summary(prueba1)
```

donde no se rechaza $H_{0}$, es decir, no hay suficiente evidencia en contra de que $0\geq \hat{\beta_{1}}$ o equivalentemente $\mu_{1}\geq \mu_{2}$. Completamos realizando dos pruebas donde se contrasta directamente

$$
H_{0}: \mu_{1}\geq \mu_{2}\ \ \ \ \ vs\ \ \ \ \  H_{a}: \mu_{1}<\mu_{2} 
$$

Para ello:

```{r}
t.test(Y ~ Med, data = Datos, alternative="less",var.equal = TRUE)
t.test(Datos$Y[Datos$Med=="Placebo"], Datos$Y[Datos$Med=="Medicamento"], alternative ="less", var.equal = TRUE)
```

no rechazándose en ambas $H_{0}$. Donde se colocó ``var.equal = TRUE`` pues en el análisis de los supuesto se concluyó que es admisible asumir que la varianza de los grupos es la misma, además es admisible asumir que la media de los grupos es diferente. Por tanto, de acuerdo a las tres pruebas de hipótesis realizadas anteriormente se concluye que no hay evidencia suficiente para argumentar en contra de que $\mu_{1}>\mu_{2}$.

#### Interpretación: 

Se concluye que no hay suficiente evidencia en contra, con una significancia de $\alpha=0.05$, de que en promedio la carga viral es mayor en aquellos pacientes que recibieron el placebo versus los pacientes que recibieron el medicamento.

iv. _Suponga ahora que dada la importancia del estudio, le han vuelto a preguntar si los resultados en el inciso III) son contundentes. Para esto, usted ha decidido analizar más el proceso de generación de los datos y ha platicado con los investigadores, logrando que le compartan una nueva variable $Edad$. Realice un análisis descriptivo y/o la visualización de los datos incluyendo esta nueva información. Comente lo que observe analizando si las conclusiones en III) se pueden_ **atribuir** _al medicamento_. 


Dado que en nuestros datos tenemos los valores ``>60`` y ```<=60`` en la columna ``Edad``, podemos realizar dos boxplots contrastando la carga viral con los datos de ``Edad`` , así como le hicimos al inicio del análisis descriptivo al contrastar la carga viral con el medicamento y el placebo. Por ende

```{r}
boxplot(Y ~ Edad, data = Datos, col = "white", outline=FALSE)
stripchart(Y ~ Edad, data = Datos,
           method = "jitter",
           pch = 19,
           col = c(4,2),
           vertical = TRUE,
           add = TRUE)
```

donde _parace_ ser que hay una relación entre la carga viral y la edad, siendo que la población de más de sesenta años tomada en la muestra de los datos _parece_ presenta mayor carga viral respecto a la población de menos de sesenta. Por ello, no podemos tener la certeza de que las conclusiones obtenidas en el inciso anterior se puedan _atribuir_ sólo al medicamento, pues el factor edad también juega un papel importante, lo cual se ve reflejado en los boxplots anteriores.

v. _Dependiendo de lo observado en IV) y si considera necesario, repita los incisos II) y III) y concluya._ 

Recordemos que la hipótesis de los investigadores es que los pacientes que recibieron el medicamento tienen menor carga viral que los que sólo recibieron placebo. Sin embargo, por lo observado en el inciso anterior parece ser que la carga viral no sólo depende del medicamento sino también de la edad. Para comprobar esto último repetiremos el inciso II) y III) realizando ahora un ajuste del modelo contrastando la carga viral con la edad. 


```{r include=FALSE}
levels(Datos$Edad)
# Convertimos la variable Med a tipo factor
Datos$Edad <- as.factor(Datos$Edad)
levels(Datos$Edad) <- list(Menor_igual_60="<=60", Mayor_60=">60")
levels(Datos$Edad)
fit2 <-lm(Y ~ Edad, data=Datos)
```

Por consiguiente, al ver los boxplots anteriores se observa cierta simetría en los datos, además de que los rangos intercuartílicos no son muy distintos y los bigotes presentan una longitud similar. Así, parece ser que los supuestos de la normalidad y la homocedasticidad se están cumpliendo. 

Para corroborrar procedemos rápidamente al análisis de los supuestos:

<ul>
<li> **Homocedasticidad:** Observamos la gráfica que ``R`` trae por defecto

```{r}
plot(fit2, 3)
```

A pesar que el primer grupo no tiene tantos datos, puede verse un comportamiento un tanto similar en los datos de ambos grupos. Complementamos lo anterior realizando pruebas de hipótesis

```{r}
lmtest::bptest(fit2)
car::ncvTest(fit2)
```

en ambos casos no se rechaza $H_{0}$ por lo que no hay suficiente evidencia en contra de la homocedasticidad. Veamos también en la prueba por grupos que


```{r}
# Prueba por grupos
bartlett.test(Y ~ Med, data=Datos)

# No paramétrica
fligner.test(Y ~ Med, data=Datos)
```

tampoco se rechaza $H_{0}$, por lo que es plausible asumir la igualdad entre varianzas. Se concluye pues que este supuesto es válido.
</li>

<li>**Normalidad**:  Observamos la Q-Qplot

```{r}
plot(fit2, 2)
```

en la que parece que el supuesto de la normalidad es válido, sin embargo podemos ver varios puntos que resaltan al no estar tan próximos a la recta. Complementamos realizando pruebas de hipótesis.

```{r}
# Cálculo de los errores
Datosfit2=augment(fit2)

# Shapiro-Wilk
shapiro.test(Datosfit2$.std.resid)

# Kolmogorov-Smirnov
nortest::lillie.test(Datosfit2$.std.resid)

# Jarque-Bera
normtest::jb.norm.test(Datosfit2$.std.resid)
```

donde no se rechaza $H_{0}$ en las tres pruebas. Hasta el momento todo parece indicar que el supuesto de la normalidad se está dando. Vemos los valores de los _p_values_ obtenidos en las pruebas por grupos

```{r include=FALSE}
# Shapiro-Wilk
shapiro.test(Datos$Y[Datos$Edad=="Menor_igual_60"])

# Kolmogorov-Smirnov
nortest::lillie.test(Datos$Y[Datos$Edad=="Menor_igual_60"])

# Jarque-Bera
normtest::jb.norm.test(Datos$Y[Datos$Edad=="Menor_igual_60"])

# Medicamento
# Shapiro-Wilk
shapiro.test(Datos$Y[Datos$Edad=="Mayor_60"])

# Kolmogorov-Smirnov
nortest::lillie.test(Datos$Y[Datos$Edad=="Mayor_60"])

# Jarque-Bera
normtest::jb.norm.test(Datos$Y[Datos$Edad=="Mayor_60"])
```


```{r results='hold'}
Prueba2 <- c("Shapiro-Wilk", "Kolmogorov-Smirnov", "Jarque-Bera")
Menor_igual_60 <- c("p-value=0.9", "p-value=0.7", "p-value=0.6")
Mayor_60 <- c("p-value=0.7", "p-value=0.6", "p-value=0.9")
d <-list()
d0 <- rbind(d,Prueba2)
d2 <- rbind(d0,Menor_igual_60)
d3 <- rbind(d2,Mayor_60)
d3
```
rechándose en todas y cada una $H_{0}$. Concluimos que el supuesto de la normalidad se cumple.
</li>
</ul>

Observemos ahora que

```{r}
summary(fit2)
```

* $\mathbb{E}[\textrm{Carga viral}; \textrm{Edad menor a 60}]=\mathbb{E}[z=0]=\hat{\beta_{0}}=14.938=\mu_{1}$

* $\mathbb{E}[\textrm{Carga viral}; \textrm{Edad mayor a 60}]=\mathbb{E}[z=1]=\hat{\beta_{0}}+\hat{\beta_{1}}=14.938+0.626=15.564=\mu_{2}$

donde puede verse que las medias son distintas y $\mu_{1}<\mu_{2}$ de acuerdo al modelo propuesto. 

Consideramos entonces la hipotesis de que la carga viral de la población con edad menor o igual a 60 es menor a la carga viral de la población con edad mayor a 60. De tal suerte es de nuestro interés contrastar
 

$$
H_{0}: \mu_{1}\leq \mu_{2}\ \ \ vs \ \ \ H_{a}: \mu_{1}>\mu_{2}
$$

o equivalentemente

$$
H_{0}: 0\leq \hat{\beta_{1}}\ \ \ vs \ \ \ H_{a}: 0>\hat{\beta_{1}}
$$

Para ello

```{r}
#theta = zo*bo + z1*b1
Mat2Z0Z1=matrix(c(0,1), ncol=2, nrow=1)

# El valor con el que comparamos a b1:
b = 0
prueba2=glht(fit2, linfct=Mat2Z0Z1, rhs=b, alternative ="less")
summary(prueba2)
```

en la que no se rechaza $H_{0}$. O contrastamos directamente

$$
H_{0}: \mu_{1}\leq \mu_{2}\ \ \ vs \ \ \ H_{a}: \mu_{1}>\mu_{2}
$$

empleando

```{r}
t.test(Y ~ Edad, data = Datos, alternative ="greater", var.equal = TRUE)
t.test(Datos$Y[Datos$Edad=="Menor_igual_60"], Datos$Y[Datos$Edad=="Mayor_60"], alternative ="greater", var.equal = TRUE)
```

en las que también no se rechaza $H_{0}$. Consideramos que no hay evidencia suficiente en contra de que $\mu_{1}<\mu_{2}$ por lo que es admisible asumir que la carga viral de la población con edad menor o igual a 60 es menor que la carga viral de la población con edad mayor a 60.

#### Conclusión:

Los resultados obtenidos en $iii$ no son contundentes pues, de acuerdo a lo hecho en el inciso $iv$ y $v$, notamos que la baja carga viral no sólo puede atribuirse al medicamento, pues ésta también depende de la edad de la población. 

### 6. Uso del modelo de regresión lineal simple 

Los $ping\ddot{u}inos$ $Macaroni$ ponen nidadas de dos huevos de tamaño
diferente. El peso en gramos de los huevos de 11 nidadas  se presenta en la tabla de abajo.

i. Ajuste la recta de regresión del peso del huevo mayor ($y$) en el peso del huevo menor  ($x$). Comente sobre el ajuste del modelo, es decir, si parece correcto y si se cumplen los supuestos. 
ii. Los investigadores tienen la sospecha de que en promedio se puede decir que la diferencia entre el peso mayor y el peso menor es constante (es decir, no depende del peso del huevo menor observado). Usando el modelo en I) realice una prueba de hipótesis para responder la pregunta de los investigadores.
iii. Posteriormente se observa el peso de los huevos de una nueva nidada, observándose un peso de 75 y  130 gramos. Usando un intervalo adecuado, comente sobre la sospecha de que la nidada de huevos sí proviene de pinguinos $Macaroni.$


```{r, echo=TRUE}

x=c(79, 93, 100, 105, 101, 96, 96, 109, 70, 71, 87)
y=c(133, 148, 164, 171, 165, 159, 162, 170, 127, 133, 148 )

Datos5=data.frame(cbind(x,y))
kable(Datos5)
```  



### 7.
Considere los datos en la base *infectionrisk.txt* y las variables: $y =$ riesgo de infección (InfctRsk) y $x =$ promedio de estancia en un hospital (Stay), sólo los datos de las regiones 1 y 2 (Region==1 | Region==2). Después de una investigación minuciosa, los responsables de la base de datos indican que todos los valores parecen reflejar la esperanza del riesgo de infección para los diferentes valores de $x$, es decir, que no se debe eliminar ninguna observación.

i. Ajustar un modelo de regresión lineal simple. Verificar los supuestos a partir de este modelo. Deberá indicar para cada
supuesto qué gráfica o prueba sirve para argumentar el cumplimiento o no
del supuesto.

ii. En caso de que alguno de los supuestos no se satisfaga en I), realizar
modificaciones a las variables para encontrar un modelo en donde sí se
satisfagan los supuestos.
    a. Para transformar la variable Y, probar con transformaciones Box-Cox
    a. Para transformar la variable X, probar con transformaciones Box-Tidwell u
otras conocidas como log() o exp().

Al finalizar, deberá indicar el modelo de regresión lineal simple que se
ajustará, haciendo explícito qué variables fueron transformadas y cómo.
También deberá indicar para cada supuesto del modelo de regresión qué
gráfica o prueba sirve para argumentar su cumplimiento.

iii. En una misma gráfica incluir los puntos en escala original, la
recta de regresión del modelo en I) y la curva del modelo en II).
iv. Interpretar $R^2$ y la prueba anova del modelo en II).
v. Con el modelo final ayude a un investigador a argumentar a favor o en
contra de la hipótesis:
"El riesgo de infección de los pacientes cuando tienen una estancia de 10 es en general mayor a 3".

